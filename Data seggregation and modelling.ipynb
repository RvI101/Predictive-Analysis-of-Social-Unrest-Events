{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import HTML\n",
    "import csv\n",
    "import dateutil.parser\n",
    "from newspaper import Article\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('bingNewsMatch.csv')\n",
    "df = shuffle(df) \n",
    "training_limit = math.ceil(len(df) * 0.8)\n",
    "validation_limit = len(df)- training_limit\n",
    "i=0\n",
    "training_data=[]\n",
    "validation_data=[]\n",
    "for index, row in df.iterrows():\n",
    "    date_pub = dateutil.parser.parse(str(row['DatePublished']))\n",
    "    if i <= training_limit:\n",
    "        arr = [date_pub,row['Name'],row['Text'],row['Label'],row['Summary'],row['Keywords']]\n",
    "        training_data.append(arr)\n",
    "    else:\n",
    "        arr = [date_pub,row['Name'],row['Text'],row['Label'],row['Summary'],row['Keywords']]\n",
    "        validation_data.append(arr)\n",
    "    i=i+1\n",
    "    if i==1065:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLeadtime():\n",
    "    count = 0\n",
    "    dateValue = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['DateLimit'] > 0 and row['DateLimit'] < 11:\n",
    "            count=count+1\n",
    "            dateValue = dateValue + row['DateLimit']\n",
    "    return math.floor(dateValue/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(ip,op):\n",
    "    for i in range(len(ip)):\n",
    "        if ip[i][3] == 1.0:\n",
    "            op.append(1)\n",
    "        else:\n",
    "            op.append(0)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextData(ip,op):\n",
    "    for i in range(len(ip)):\n",
    "        op.append(ip[i][5])\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "print(len(validation_data))\n",
    "training_labels = []\n",
    "validation_labels = []\n",
    "validation_Features=[]\n",
    "training_Features =[]\n",
    "\n",
    "training_labels = getLabels(training_data,training_labels)\n",
    "validation_labels = getLabels(validation_data,validation_labels)\n",
    "training_Features = getTextData(training_data,training_Features)\n",
    "validation_Features = getTextData(training_data,validation_Features)\n",
    "\n",
    "whole_data = []\n",
    "whole_labels = []\n",
    "for index, row in df.iterrows():\n",
    "    date_pub = dateutil.parser.parse(row['DatePublished'])\n",
    "    arr = [date_pub,row['Name'],row['Text'],row['Label'],row['Summary'],row['Keywords']]\n",
    "    if row['Keywords'] is np.nan:\n",
    "        whole_data.append(\"\")\n",
    "    else:\n",
    "        whole_data.append(row['Keywords'])\n",
    "    if row['Label'] == 1.0:\n",
    "        whole_labels.append(1)\n",
    "    else:\n",
    "        whole_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhayanidhigunasekaran/anaconda/lib/python3.5/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "        \n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(np.array(whole_data), np.array(whole_labels), test_size=0.1, random_state=42)\n",
    "sample_art = [\"SRINAGAR, India (AP) - Anti-India protests and clashes erupted in disputed Kashmir on Saturday after a gunbattle between militants and government forces killed four rebels, police and residents said.According to rights groups, they include at least 269 militants, 158 members of Indian government forces and 156 civilians.Indian troops early Saturday surrounded a southern village in the Pulwama area on a tip that militants were hiding there, leading to an exchange of gunfire, police said.Residents said government forces blasted one civilian house with explosives during the fighting, a common counterinsurgency tactic by Indian troops in Kashmir.Rebels have been fighting Indian control since 1989.\"]\n",
    "\n",
    "\n",
    "### text vectorization--go from strings to lists of numbers\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "features_test_transformed  = vectorizer.transform(features_test)\n",
    "sample_article = vectorizer.transform(sample_art)\n",
    "\n",
    "### feature selection, because text is super high dimensional and \n",
    "### can be really computationally chewy as a result\n",
    "selector = SelectPercentile(f_classif, percentile=25)\n",
    "selector.fit(features_train_transformed, labels_train)\n",
    "features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "sample_article = selector.transform(sample_article).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train_transformed, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possiblity of protests \n"
     ]
    }
   ],
   "source": [
    "if clf.predict(sample_article) == 1:\n",
    "    print(\"possiblity of protests \")\n",
    "else:\n",
    "    print(\"No possibility of protests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(getLeadtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8504672897196262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(features_train, labels_train)\n",
    "\n",
    "y_pred = sgd.predict(features_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.80      0.85        59\n",
      "          0       0.79      0.92      0.85        48\n",
      "\n",
      "avg / total       0.86      0.85      0.85       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_tags = ['1','0']\n",
    "print(classification_report(labels_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8504672897196262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.83      0.86        59\n",
      "          0       0.81      0.88      0.84        48\n",
      "\n",
      "avg / total       0.85      0.85      0.85       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(features_train, labels_train)\n",
    "\n",
    "y_pred = logreg.predict(features_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, labels_test))\n",
    "print(classification_report(labels_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8317757009345794\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.75      0.83        59\n",
      "          0       0.75      0.94      0.83        48\n",
      "\n",
      "avg / total       0.85      0.83      0.83       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(features_train, labels_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(features_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, labels_test))\n",
    "print(classification_report(labels_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "df.Label.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
